{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import Libraries, Initialize Models, etc\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 96,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
                "from langchain_core.documents import Document\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from qdrant_client import QdrantClient\n",
                "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
                "\n",
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "load_dotenv(\"../.env\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[-0.042558297514915466, -0.06038237363100052, 0.03893209621310234]"
                        ]
                    },
                    "execution_count": 97,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_name = \"BAAI/bge-base-en-v1.5\"\n",
                "\n",
                "embedding_model = HuggingFaceInferenceAPIEmbeddings(\n",
                "    api_key=os.getenv(\"HUGGINGFACE_API_KEY\"), model_name=model_name\n",
                ")\n",
                "\n",
                "# test if embedding model works\n",
                "res = embedding_model.embed_query(\"The quick brown fox jumps over the lazy dog\")\n",
                "res[:3]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process Standard Sheets\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                                   0\n",
                        "0                                   [H1] TENTANG ITB\n",
                        "1  Institut Teknologi Bandung (ITB) merupakan sek...\n",
                        "2                                       [H1] Sejarah\n",
                        "3  Sejarah Pendidikan Tinggi Teknik di Indonesia ...\n",
                        "4  Sejak resmi dibuka untuk tahun kuliah 1920-192...\n"
                    ]
                }
            ],
            "source": [
                "filepath = \"xlsx/[ANNOTATED] Informasi Umum ITB.xlsx\"\n",
                "\n",
                "\n",
                "# standard sheets: readable ones with one column\n",
                "standard_sheets = [\n",
                "    \"Tentang ITB\",\n",
                "    \"Penerimaan\",\n",
                "    # \"Pendidikan\",\n",
                "    \"Penelitian\",\n",
                "    \"Pengabdian\",\n",
                "    \"Multikampus\",\n",
                "    \"FAQ\",\n",
                "]\n",
                "\n",
                "\n",
                "def read_dfs(sheet_names: list[str]) -> dict[str, pd.DataFrame]:\n",
                "    filepath = \"xlsx/[ANNOTATED] Informasi Umum ITB.xlsx\"\n",
                "    dfs = pd.read_excel(filepath, sheet_name=sheet_names)\n",
                "\n",
                "    for name in sheet_names:\n",
                "        # for each df, drop a row if the entire row is null\n",
                "        # also drop cells with the content \"kembali ke halaman utama\"\n",
                "        dfs[name] = dfs[name].dropna(how=\"all\").reset_index(drop=True)\n",
                "        dfs[name] = dfs[name][\n",
                "            ~dfs[name].iloc[:, 0].str.contains(\"Kembali ke Halaman Utama\")\n",
                "        ]\n",
                "\n",
                "        # do not make the first row as the title of the column\n",
                "        dfs[name].columns = range(dfs[name].shape[1])\n",
                "\n",
                "    return dfs\n",
                "\n",
                "\n",
                "# read standard sheets\n",
                "standard_dfs = read_dfs(standard_sheets)\n",
                "\n",
                "\n",
                "# print the first df for sanity check\n",
                "print(standard_dfs[standard_sheets[0]].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_standard_sheets(sheet_name: str, df: pd.DataFrame):\n",
                "    # we want to read cell by cell: there is only one column in this dataframe\n",
                "    # essentially, we want to group the content between cells with the tag [H1]\n",
                "    # get the indices of the cells with the tag [H1]\n",
                "    documents = []\n",
                "    h1_indices = df[df.iloc[:, 0].str.contains(\"\\[H1\\]\")].index\n",
                "\n",
                "    for i in range(len(h1_indices)):\n",
                "        index = h1_indices[i]\n",
                "        next_idx = h1_indices[i + 1] if i + 1 < len(h1_indices) else len(df)\n",
                "\n",
                "        # get the title and the content of the part between the [H1] tags\n",
                "        title = df.iloc[index, 0]\n",
                "        content = \" \".join(df.iloc[index + 1 : next_idx, 0].values)\n",
                "\n",
                "        documents.append(\n",
                "            Document(\n",
                "                page_content=content,\n",
                "                metadata={\"title\": title, \"sheet_name\": sheet_name},\n",
                "            )\n",
                "        )\n",
                "    return documents\n",
                "\n",
                "\n",
                "all_documents = []\n",
                "\n",
                "for sheet_name, df in standard_dfs.items():\n",
                "    docs = process_standard_sheets(sheet_name, df)\n",
                "    all_documents.extend(docs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Embedding and Inserting to Vector Database\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_texts = [doc.page_content for doc in all_documents]\n",
                "\n",
                "embeddings = [embedding_model.embed_query(text) for text in input_texts]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_65809/3998955497.py:4: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
                        "  client.recreate_collection(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
                        ]
                    },
                    "execution_count": 104,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "client = QdrantClient(os.getenv(\"VECTOR_DB_ENDPOINT\"))\n",
                "\n",
                "\n",
                "client.recreate_collection(\n",
                "    collection_name=\"informasi_umum\",\n",
                "    vectors_config=VectorParams(size=len(embeddings[0]), distance=Distance.COSINE),\n",
                ")\n",
                "\n",
                "client.upsert(\n",
                "    collection_name=\"informasi_umum\",\n",
                "    points=[\n",
                "        PointStruct(\n",
                "            id=i,\n",
                "            vector=vector,\n",
                "            payload={\n",
                "                \"page_content\": all_documents[i].page_content,\n",
                "                \"metadata\": all_documents[i].metadata,\n",
                "            },\n",
                "        )\n",
                "        for i, vector in enumerate(embeddings)\n",
                "    ],\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
